{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\programdata\\anaconda3\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (3.1.1)\n",
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (6.2.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from wordcloud) (1.16.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->wordcloud) (1.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->wordcloud) (41.4.0)\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.4.5)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.12.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\ASTHA\n",
      "[nltk_data]     DWIVEDI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10314 entries, 0 to 10313\n",
      "Data columns (total 2 columns):\n",
      "message    10314 non-null object\n",
      "label      10314 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 161.3+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10314 entries, 0 to 10313\n",
      "Data columns (total 2 columns):\n",
      "message    10314 non-null object\n",
      "label      10314 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 161.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8387096774193549\n",
      "Recall:  0.5531914893617021\n",
      "F-score:  0.6666666666666666\n",
      "Accuracy:  0.8755980861244019\n",
      "Precision:  0.8125\n",
      "Recall:  0.2765957446808511\n",
      "F-score:  0.4126984126984127\n",
      "Accuracy:  0.8229665071770335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install wordcloud\n",
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from math import log, sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "# %matplotlib inline\n",
    "\n",
    "\"\"\"# Loading the Data\"\"\"\n",
    "\n",
    "tweets = pd.read_csv('sentiment_tweets3.csv')\n",
    "tweets.head(20)\n",
    "\n",
    "tweets.drop(['Unnamed: 0'], axis = 1, inplace = True)\n",
    "\n",
    "tweets['label'].value_counts()\n",
    "\n",
    "tweets.info()\n",
    "\n",
    "\"\"\"# Splitting the Data in Training and Testing Sets\n",
    "As you can see, I used almost all the data for training: 98% and the rest for testing.\n",
    "\"\"\"\n",
    "\n",
    "totalTweets = 8000 + 2314\n",
    "trainIndex, testIndex = list(), list()\n",
    "for i in range(tweets.shape[0]):\n",
    "    if np.random.uniform(0, 1) < 0.98:\n",
    "        trainIndex += [i]\n",
    "    else:\n",
    "        testIndex += [i]\n",
    "trainData = tweets.iloc[trainIndex]\n",
    "testData = tweets.iloc[testIndex]\n",
    "\n",
    "tweets.info()\n",
    "\n",
    "trainData['label'].value_counts()\n",
    "\n",
    "trainData.head()\n",
    "\n",
    "testData['label'].value_counts()\n",
    "\n",
    "testData.head()\n",
    "\n",
    "\"\"\"# Wordcloud Analysis\"\"\"\n",
    "\n",
    "depressive_words = ' '.join(list(tweets[tweets['label'] == 1]['message']))\n",
    "depressive_wc = WordCloud(width = 512,height = 512, collocations=False, colormap=\"Blues\").generate(depressive_words)\n",
    "plt.figure(figsize = (10, 8), facecolor = 'k')\n",
    "plt.imshow(depressive_wc)\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()\n",
    "\n",
    "positive_words = ' '.join(list(tweets[tweets['label'] == 0]['message']))\n",
    "positive_wc = WordCloud(width = 512,height = 512, collocations=False, colormap=\"Blues\").generate(positive_words)\n",
    "plt.figure(figsize = (10, 8), facecolor = 'k')\n",
    "plt.imshow(positive_wc)\n",
    "plt.axis('off'), \n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()\n",
    "\n",
    "\"\"\"#Pre-processing the data for the training: Tokenization, stemming, and removal of stop words\"\"\"\n",
    "\n",
    "def process_message(message, lower_case = True, stem = True, stop_words = True, gram = 2):\n",
    "    if lower_case:\n",
    "        message = message.lower()\n",
    "    words = word_tokenize(message)\n",
    "    words = [w for w in words if len(w) > 2]\n",
    "    if gram > 1:\n",
    "        w = []\n",
    "        for i in range(len(words) - gram + 1):\n",
    "            w += [' '.join(words[i:i + gram])]\n",
    "        return w\n",
    "    if stop_words:\n",
    "        sw = stopwords.words('english')\n",
    "        words = [word for word in words if word not in sw]\n",
    "    if stem:\n",
    "        stemmer = PorterStemmer()\n",
    "        words = [stemmer.stem(word) for word in words]   \n",
    "    return words\n",
    "\n",
    "class TweetClassifier(object):\n",
    "    def __init__(self, trainData, method = 'tf-idf'):\n",
    "        self.tweets, self.labels = trainData['message'], trainData['label']\n",
    "        self.method = method\n",
    "\n",
    "    def train(self):\n",
    "        self.calc_TF_and_IDF()\n",
    "        if self.method == 'tf-idf':\n",
    "            self.calc_TF_IDF()\n",
    "        else:\n",
    "            self.calc_prob()\n",
    "\n",
    "    def calc_prob(self):\n",
    "        self.prob_depressive = dict()\n",
    "        self.prob_positive = dict()\n",
    "        for word in self.tf_depressive:\n",
    "            self.prob_depressive[word] = (self.tf_depressive[word] + 1) / (self.depressive_words + \\\n",
    "                                                                len(list(self.tf_depressive.keys())))\n",
    "        for word in self.tf_positive:\n",
    "            self.prob_positive[word] = (self.tf_positive[word] + 1) / (self.positive_words + \\\n",
    "                                                                len(list(self.tf_positive.keys())))\n",
    "        self.prob_depressive_tweet, self.prob_positive_tweet = self.depressive_tweets / self.total_tweets, self.positive_tweets / self.total_tweets \n",
    "\n",
    "\n",
    "    def calc_TF_and_IDF(self):\n",
    "        noOfMessages = self.tweets.shape[0]\n",
    "        self.depressive_tweets, self.positive_tweets = self.labels.value_counts()[1], self.labels.value_counts()[0]\n",
    "        self.total_tweets = self.depressive_tweets + self.positive_tweets\n",
    "        self.depressive_words = 0\n",
    "        self.positive_words = 0\n",
    "        self.tf_depressive = dict()\n",
    "        self.tf_positive = dict()\n",
    "        self.idf_depressive = dict()\n",
    "        self.idf_positive = dict()\n",
    "        for i in range(noOfMessages):\n",
    "            message_processed = process_message(self.tweets.iloc[i])\n",
    "            count = list() #To keep track of whether the word has ocured in the message or not.\n",
    "                           #For IDF\n",
    "            for word in message_processed:\n",
    "                if self.labels.iloc[i]:\n",
    "                    self.tf_depressive[word] = self.tf_depressive.get(word, 0) + 1\n",
    "                    self.depressive_words += 1\n",
    "                else:\n",
    "                    self.tf_positive[word] = self.tf_positive.get(word, 0) + 1\n",
    "                    self.positive_words += 1\n",
    "                if word not in count:\n",
    "                    count += [word]\n",
    "            for word in count:\n",
    "                if self.labels.iloc[i]:\n",
    "                    self.idf_depressive[word] = self.idf_depressive.get(word, 0) + 1\n",
    "                else:\n",
    "                    self.idf_positive[word] = self.idf_positive.get(word, 0) + 1\n",
    "\n",
    "    def calc_TF_IDF(self):\n",
    "        self.prob_depressive = dict()\n",
    "        self.prob_positive = dict()\n",
    "        self.sum_tf_idf_depressive = 0\n",
    "        self.sum_tf_idf_positive = 0\n",
    "        for word in self.tf_depressive:\n",
    "            self.prob_depressive[word] = (self.tf_depressive[word]) * log((self.depressive_tweets + self.positive_tweets) \\\n",
    "                                                          / (self.idf_depressive[word] + self.idf_positive.get(word, 0)))\n",
    "            self.sum_tf_idf_depressive += self.prob_depressive[word]\n",
    "        for word in self.tf_depressive:\n",
    "            self.prob_depressive[word] = (self.prob_depressive[word] + 1) / (self.sum_tf_idf_depressive + len(list(self.prob_depressive.keys())))\n",
    "            \n",
    "        for word in self.tf_positive:\n",
    "            self.prob_positive[word] = (self.tf_positive[word]) * log((self.depressive_tweets + self.positive_tweets) \\\n",
    "                                                          / (self.idf_depressive.get(word, 0) + self.idf_positive[word]))\n",
    "            self.sum_tf_idf_positive += self.prob_positive[word]\n",
    "        for word in self.tf_positive:\n",
    "            self.prob_positive[word] = (self.prob_positive[word] + 1) / (self.sum_tf_idf_positive + len(list(self.prob_positive.keys())))\n",
    "            \n",
    "    \n",
    "        self.prob_depressive_tweet, self.prob_positive_tweet = self.depressive_tweets / self.total_tweets, self.positive_tweets / self.total_tweets \n",
    "                    \n",
    "    def classify(self, processed_message):\n",
    "        pDepressive, pPositive = 0, 0\n",
    "        for word in processed_message:                \n",
    "            if word in self.prob_depressive:\n",
    "                pDepressive += log(self.prob_depressive[word])\n",
    "            else:\n",
    "                if self.method == 'tf-idf':\n",
    "                    pDepressive -= log(self.sum_tf_idf_depressive + len(list(self.prob_depressive.keys())))\n",
    "                else:\n",
    "                    pDepressive -= log(self.depressive_words + len(list(self.prob_depressive.keys())))\n",
    "            if word in self.prob_positive:\n",
    "                pPositive += log(self.prob_positive[word])\n",
    "            else:\n",
    "                if self.method == 'tf-idf':\n",
    "                    pPositive -= log(self.sum_tf_idf_positive + len(list(self.prob_positive.keys()))) \n",
    "                else:\n",
    "                    pPositive -= log(self.positive_words + len(list(self.prob_positive.keys())))\n",
    "            pDepressive += log(self.prob_depressive_tweet)\n",
    "            pPositive += log(self.prob_positive_tweet)\n",
    "        return pDepressive >= pPositive\n",
    "    \n",
    "    def predict(self, testData):\n",
    "        result = dict()\n",
    "        for (i, message) in enumerate(testData):\n",
    "            processed_message = process_message(message)\n",
    "            result[i] = int(self.classify(processed_message))\n",
    "        return result\n",
    "\n",
    "def metrics(labels, predictions):\n",
    "    true_pos, true_neg, false_pos, false_neg = 0, 0, 0, 0\n",
    "    for i in range(len(labels)):\n",
    "        true_pos += int(labels.iloc[i] == 1 and predictions[i] == 1)\n",
    "        true_neg += int(labels.iloc[i] == 0 and predictions[i] == 0)\n",
    "        false_pos += int(labels.iloc[i] == 0 and predictions[i] == 1)\n",
    "        false_neg += int(labels.iloc[i] == 1 and predictions[i] == 0)\n",
    "    precision = true_pos / (true_pos + false_pos)\n",
    "    recall = true_pos / (true_pos + false_neg)\n",
    "    Fscore = 2 * precision * recall / (precision + recall)\n",
    "    accuracy = (true_pos + true_neg) / (true_pos + true_neg + false_pos + false_neg)\n",
    "\n",
    "    print(\"Precision: \", precision)\n",
    "    print(\"Recall: \", recall)\n",
    "    print(\"F-score: \", Fscore)\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "\n",
    "sc_tf_idf = TweetClassifier(trainData, 'tf-idf')\n",
    "sc_tf_idf.train()\n",
    "preds_tf_idf = sc_tf_idf.predict(testData['message'])\n",
    "metrics(testData['label'], preds_tf_idf)\n",
    "\n",
    "sc_bow = TweetClassifier(trainData, 'bow')\n",
    "sc_bow.train()\n",
    "preds_bow = sc_bow.predict(testData['message'])\n",
    "metrics(testData['label'], preds_bow)\n",
    "\n",
    "\"\"\"# Predictions with TF-IDF\n",
    "# Depressive Tweets\n",
    "\"\"\"\n",
    "\n",
    "pm = process_message('Lately I have been feeling unsure of myself as a person & an artist')\n",
    "sc_tf_idf.classify(pm)\n",
    "\n",
    "pm = process_message('Extreme sadness, lack of energy, hopelessness')\n",
    "sc_tf_idf.classify(pm)\n",
    "\n",
    "pm = process_message('Hi hello depression and anxiety are the worst')\n",
    "sc_tf_idf.classify(pm)\n",
    "\n",
    "pm = process_message('I am officially done with @kanyewest')\n",
    "sc_tf_idf.classify(pm)\n",
    "\n",
    "pm = process_message('Feeling down...')\n",
    "sc_tf_idf.classify(pm)\n",
    "\n",
    "pm = process_message('My depression will not let me work out')\n",
    "sc_tf_idf.classify(pm)\n",
    "\n",
    "\"\"\"# Positive Tweets\"\"\"\n",
    "\n",
    "pm = process_message('Loving how me and my lovely partner is talking about what we want.')\n",
    "sc_tf_idf.classify(pm)\n",
    "\n",
    "pm = process_message('Very rewarding when a patient hugs you and tells you they feel great after changing the diet and daily habits')\n",
    "sc_tf_idf.classify(pm)\n",
    "\n",
    "pm = process_message('Happy Thursday everyone. Thought today was Wednesday so super happy tomorrow is Friday yayyyyy')\n",
    "sc_tf_idf.classify(pm)\n",
    "\n",
    "pm = process_message('Itâ€™s the little things that make me smile. Got our new car today and this arrived with it')\n",
    "sc_tf_idf.classify(pm)\n",
    "\n",
    "\"\"\"# Predictions with Bag-of-Words (BOW)\n",
    "# Depressive tweets\n",
    "\"\"\"\n",
    "\n",
    "pm = process_message('Hi hello depression and anxiety are the worst')\n",
    "sc_bow.classify(pm)\n",
    "\n",
    "pm = process_message('My depression will not let me work out')\n",
    "sc_bow.classify(pm)\n",
    "\n",
    "pm = process_message('Feeling down...')\n",
    "sc_bow.classify(pm)\n",
    "\n",
    "\"\"\"# Positive Tweets\"\"\"\n",
    "\n",
    "pm = process_message('Loving how me and my lovely partner is talking about what we want.')\n",
    "sc_bow.classify(pm)\n",
    "\n",
    "pm = process_message('Very rewarding when a patient hugs you and tells you they feel great after changing the diet and daily habits')\n",
    "sc_bow.classify(pm)\n",
    "\n",
    "pm = process_message('Happy Thursday everyone. Thought today was Wednesday so super happy tomorrow is Friday yayyyyy')\n",
    "sc_bow.classify(pm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
